{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling Data Stage\n",
    "\n",
    "We need to go website https://www.cbs.gov.il\n",
    "Our data is in 'תמותה-ותוחלת-חיים' page and 'לידות-חי' page.\n",
    "To work and cleen the data we need to downlod those files.\n",
    " \n",
    "Beacuse our web suffix in .apxs we used Selenium.\n",
    "We then got excle data.\n",
    "\n",
    "This is the link of toturial Selenium https://www.jcchouinard.com/learn-selenium-python-seo-automation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selenium_crawling(url, element_xpath, typh):\n",
    "    driver=webdriver.Chrome(executable_path=r\"/Applications/Google Chrome.app/Contents/MacOS/chromedriver\")\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    linkText=driver.find_element_by_xpath(element_xpath)\n",
    "    linkText.get_attribute(typh)\n",
    "    linkText.click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = 'https://www.cbs.gov.il/he/subjects/Pages/תמותה-ותוחלת-חיים.aspx'\n",
    "element_xpath_1 = \"/html/body/form/div[3]/div/div/main/div/div[3]/div[1]/div/div[1]/div[6]/div[1]/ul/li[3]/div/div[1]/a\"\n",
    "typh_1 = \"href\"\n",
    "selenium_crawling(url_1, element_xpath_1, typh_1)\n",
    "\n",
    "url_2 = 'https://www.cbs.gov.il/he/subjects/Pages/לידות-חי.aspx'\n",
    "element_xpath_2 = \"/html/body/form/div[3]/div/div/main/div/div[3]/div[1]/div/div[1]/div[6]/div[1]/ul/li[2]/div/div[1]/a\"\n",
    "typh_2 = \"href\"\n",
    "selenium_crawling(url_2, element_xpath_2, typh_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data Stage\n",
    "\n",
    "\n",
    "After we downlod the excle files we move them to the same folder with this notebook.\n",
    "\n",
    "Convert the Data Frame from an Excel table to csv.\n",
    "we built functions to handle the data of the two tables we took out of the site\n",
    " we erasure all the rows and Columns that was irrelevant to our research question.\n",
    "following the merger of the cells that existed in the original df, it was necessary to rename sane Columns name.\n",
    "\n",
    "The mortality table presented the deaths each day, In order to unite the cells We changed the cell name from the date to  only his year.\n",
    "Using a function  groupby we summed all the lines of all year into one line.\n",
    "Concatenation the mortality df and Birth data to one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_excel_tab_to_csv(year):\n",
    "    df=pd.read_excel(io='p-1.xlsx',sheet_name=year)\n",
    "    df.to_csv(year+'.csv',index=False)\n",
    "    return df\n",
    "    \n",
    "def clean_daeth_data(df,year_csv,row_drop,col_drop):\n",
    "    if row_drop != None:\n",
    "        df.drop(labels=row_drop, axis=0, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df.index = range(len(df))\n",
    "    if col_drop != None:\n",
    "        df.drop(columns=col_drop, axis=0, inplace=True)\n",
    "        df.rename({'Unnamed: 0':'year','Unnamed: 1':'total_death','Unnamed: 4':'Jews_and_others_total_death',\n",
    "                   'Unnamed: 7':'Arabs_total_death'}, axis=1, inplace=True)\n",
    "    df.year = year_csv\n",
    "    df = df.applymap(np.int64)\n",
    "    df.to_csv(year_csv+'.csv',index=False)\n",
    "    return df\n",
    "\n",
    "def clean_born_data(df,df_name,row_drop,col_drop,col_new_name):\n",
    "    df = df.T\n",
    "    if row_drop != None:\n",
    "        df.drop(labels=row_drop, axis=0, inplace=True)\n",
    "    if col_drop != None:\n",
    "        df.drop(columns=col_drop, axis=0, inplace=True)\n",
    "        df.columns = [col_new_name]\n",
    "    df = add_empty_row_to_top(df,2)\n",
    "    df = add_empty_row_to_end(df,2)\n",
    "    df = df.applymap(np.int64)\n",
    "    df.index = range(2000,2022)\n",
    "    df.to_csv(df_name+'.csv')\n",
    "    return df\n",
    "\n",
    "def clean_data_dropna(df,axis_1_0):\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def clean_rows_data(df,column_to_clean,max_num):\n",
    "    for row in df.loc[column_to_clean]:\n",
    "        df.loc[df[row] > max_num] = np.nan\n",
    "    return df\n",
    "\n",
    "def clean_columns_data(df,columns_list):\n",
    "    df.drop(columns=columns_list, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def gropby_data(df,column_grop,column_to_sum):\n",
    "    df1 = df.groupby(column_grop)[column_to_sum].apply(lambda x : x.astype(int).sum())\n",
    "    return df1\n",
    "\n",
    "def add_empty_row_to_top(df,num_to_add):\n",
    "    i=1\n",
    "    for i in range(1,num_to_add+1):\n",
    "        df1 = pd.DataFrame([[0] * len(df.columns)], columns=df.columns)\n",
    "        df = df1.append(df, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def add_empty_row_to_end(df,num_to_add):\n",
    "    i=1\n",
    "    for i in range(1,num_to_add+1):\n",
    "        df1 = pd.DataFrame([[0] * len(df.columns)], columns=df.columns)\n",
    "        df = df.append(df1, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'p-1.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-369b9f719563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_excel_tab_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c8db9304ebb5>\u001b[0m in \u001b[0;36mconvert_excel_tab_to_csv\u001b[0;34m(year)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_excel_tab_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'p-1.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'p-1.xlsx'"
     ]
    }
   ],
   "source": [
    "list_df = []\n",
    "for i in range(2000,2022):\n",
    "    df = convert_excel_tab_to_csv(str(i))\n",
    "    file_name = str(i)+'.csv'\n",
    "    df = pd.read_csv(file_name,low_memory=False)\n",
    "    row_to_drop = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "    col_to_drop = ['Unnamed: 2','Unnamed: 3','Unnamed: 5','Unnamed: 6','Unnamed: 8','Unnamed: 9','Unnamed: 10',\n",
    "                   'Unnamed: 11','Unnamed: 12','Unnamed: 13','Unnamed: 14','Unnamed: 15','Unnamed: 16',\n",
    "                   'Unnamed: 17','Unnamed: 18','Unnamed: 19','Unnamed: 20','Unnamed: 21','Unnamed: 22',\n",
    "                   'Unnamed: 23','Unnamed: 24','Unnamed: 25']\n",
    "    df = clean_daeth_data(df,str(i),row_to_drop,col_to_drop)\n",
    "    list_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat(list_df)\n",
    "df_total.to_csv('2000-2021.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_grop = 'year'\n",
    "column_to_sum = [\"total_death\",\"Jews_and_others_total_death\",\"Arabs_total_death\"]\n",
    "df_total = gropby_data(df_total,column_grop,column_to_sum)\n",
    "df_total.index = range(2000,2022)\n",
    "df_total.to_csv('2000-2021_total.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'lidot_all_1'\n",
    "df_born = pd.read_excel(io=df_name+'.xls')\n",
    "df_born = df_born.to_csv(df_name+'.csv',index=False)\n",
    "df_born = pd.read_csv(df_name+'.csv',low_memory=False)\n",
    "row_to_drop = ['Unnamed: 0','Unnamed: 19']\n",
    "col_to_drop = [0,1,2,3,4,5,7,8,9,10,12,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55]\n",
    "col_new_name = ['total_born','Jews_and_others_total_born','Arabs_total_born']\n",
    "df_born = clean_born_data(df_born,df_name,row_to_drop,col_to_drop,col_new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_total_merge = pd.concat([df_total,df_born], axis=1, join=\"inner\")\n",
    "\n",
    "df_total_merge.columns = [\"total_death\",\"Jews_and_others_total_death\",\"Arabs_total_death\",'total_born',\n",
    "                       'Jews_and_others_total_born','Arabs_total_born']\n",
    "df_total_merge.replace(0, np.nan, inplace=True)\n",
    "df_total_merge.dropna(how='any',inplace=True)\n",
    "df_total_merge.to_csv('2000-2021_total_merge.csv',index=True)\n",
    "print(df_total_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA stage\n",
    "\n",
    "\n",
    "In this stage we creat a new df for our pei and bar plot.\n",
    "We what to show in pei plot in which year the data of Jews and Arabs death and born.\n",
    "In the bar plot we showed the death and born on which one of the sectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pei(df,x_len,y_len):\n",
    "    colors = ['m', 'c']\n",
    "    labels_1 = ['Jews_and_others_total_death', 'Arabs_total_death']\n",
    "    labels_2 = ['Jews_and_others_total_born', 'Arabs_total_born']\n",
    "    for row in range(2009,2020):\n",
    "        year = df.loc[row]    \n",
    "        df1 = pd.DataFrame([year['Jews_and_others_total_death'],year['Arabs_total_death']],\n",
    "                            index=['Jews_and_others_total_death','Arabs_total_death'], columns=[row]) \n",
    "        \n",
    "        plot_1 = df1.plot.pie(figsize=(5,5),subplots=True,autopct='%1.1f%%',colors=colors)\n",
    "        print(plot_1)\n",
    "\n",
    "        df2 = pd.DataFrame([year['Jews_and_others_total_born'],year['Arabs_total_born']],\n",
    "                             index=['Jews_and_others_total_born', 'Arabs_total_born'], columns=[row])\n",
    "        \n",
    "        plot_2 = df2.plot.pie(figsize=(5,5),subplots=True,autopct='%1.1f%%',colors=colors)\n",
    "        print(plot_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_len,y_len = 11,2\n",
    "plot_pei(df_total_merge,x_len,y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(df):\n",
    "    df_Arabs = df.copy()\n",
    "    df_Arabs.drop(columns=['total_death','total_born','Jews_and_others_total_death','Jews_and_others_total_born'],inplace=True)\n",
    "    df_Jews = df.copy()\n",
    "    df_Jews.drop(columns=['total_death','total_born','Arabs_total_death','Arabs_total_born'],inplace=True)\n",
    "    ax_1 = df_Arabs.plot.bar(rot=0,figsize = (20,10))\n",
    "    ax_2 = df_Jews.plot.bar(rot=0,figsize = (20,10))\n",
    "    print(ax_1)\n",
    "    print(ax_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar(df_total_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machin Lerning Stage\n",
    "\n",
    "\n",
    "We want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X,y,split, ratio):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=ratio)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def creat_colum(df,name_new_col,data_col):\n",
    "    df[name_new_col] = data_col\n",
    "    return df\n",
    "\n",
    "def convert_to_precent(df,col_name):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat new columns on death-born on each one\n",
    "name_new_col = 'Jews_and_others_total_death_born'\n",
    "data_col = ((df_total_merge['Jews_and_others_total_death'] - df_total_merge['Jews_and_others_total_born']) * (-1))\n",
    "df_total_merge = creat_colum(df_total_merge,name_new_col,data_col)\n",
    "\n",
    "name_new_col = 'Arabs_total_death_born'\n",
    "data_col = ((df_total_merge['Arabs_total_death'] - df_total_merge['Arabs_total_born']) * (-1))\n",
    "df_total_merge = creat_colum(df_total_merge,name_new_col,data_col)\n",
    "\n",
    "name_new_col = 'total_death_born'\n",
    "data_col = ((df_total_merge['total_death'] - df_total_merge['total_born']) * (-1))\n",
    "df_total_merge = creat_colum(df_total_merge,name_new_col,data_col)\n",
    "\n",
    "# creat new columns on precent death and born on each one\n",
    "name_new_col = 'Jews_and_others_total_death_born_precent'\n",
    "data_col = (df_total_merge['Jews_and_others_total_death_born'] / df_total_merge['total_death_born'])\n",
    "df_total_merge = creat_colum(df_total_merge,name_new_col,data_col)\n",
    "\n",
    "name_new_col = 'Arabs_total_death_born_precent'\n",
    "data_col = (df_total_merge['Arabs_total_death_born'] / df_total_merge['total_death_born'])\n",
    "df_total_merge = creat_colum(df_total_merge,name_new_col,data_col)\n",
    "\n",
    "df_total_merge.to_csv('2000-2021_total_merge.csv',index=True)\n",
    "\n",
    "df_total_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_total_merge['Jews_and_others_total_death'],y=df_total_merge['Jews_and_others_total_born'],c='m',marker='s',label='Jews')\n",
    "plt.scatter(x=df_total_merge['Arabs_total_death'],y=df_total_merge['Arabs_total_born'],c='c',marker='s',label='Jews')\n",
    "\n",
    "\n",
    "plt.legend(numpoints=1,loc=4)\n",
    "plt.xlabel('Jews Death (Thousands)')\n",
    "plt.ylabel('Jews born (Thousands)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_Jews = linear_model.LinearRegression() # create a linear regression object\n",
    "\n",
    "# scikit-learn doesn't work as well with pandas, so we have to extract values \n",
    "x = df_total_merge['Jews_and_others_total_death'].values.reshape(df_total_merge['Jews_and_others_total_death'].shape[0],1)\n",
    "y = df_total_merge['Jews_and_others_total_born'].values.reshape(df_total_merge['Jews_and_others_total_born'].shape[0],1)\n",
    "\n",
    "lr_Jews.fit(X=x, y=y)\n",
    "\n",
    "plt.scatter(x, y,  color='m')\n",
    "plt.plot(x, lr_Jews.predict(x), color='pink', linewidth=2)\n",
    "\n",
    "plt.xlabel('Jews death (Thousands)')\n",
    "plt.ylabel('Jews born (Thousands)')\n",
    "plt.show()\n",
    "\n",
    "print(\"Slope:\",lr_Jews.coef_)\n",
    "print(\"Intercept:\",lr_Jews.intercept_)\n",
    "print(\"R2:\",lr_Jews.score(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_total_merge.Jews_and_others_total_born.tolist(),m.predict(df_total_merge.iloc[:,1:2]).flatten())*len(df_total_merge.Jews_and_others_total_born.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_Arabs = linear_model.LinearRegression() # create a linear regression object\n",
    "\n",
    "# scikit-learn doesn't work as well with pandas, so we have to extract values \n",
    "x = df_total_merge['Arabs_total_death'].values.reshape(df_total_merge['Arabs_total_death'].shape[0],1)\n",
    "y = df_total_merge['Arabs_total_born'].values.reshape(df_total_merge['Arabs_total_born'].shape[0],1)\n",
    "\n",
    "lr_Arabs.fit(X=x, y=y)\n",
    "\n",
    "plt.scatter(x, y,  color='c')\n",
    "plt.plot(x, lr_Arabs.predict(x), color='blue', linewidth=2)\n",
    "\n",
    "plt.xlabel('Arabs death (Thousands)')\n",
    "plt.ylabel('Arabs born (Thousands)')\n",
    "plt.show()\n",
    "\n",
    "print(\"Slope:\",lr_Arabs.coef_)\n",
    "print(\"Intercept:\",lr_Arabs.intercept_)\n",
    "print(\"R2:\",lr_Arabs.score(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(df_total_merge.Arabs_total_born.tolist(),m.predict(df_total_merge.iloc[:,2:3]).flatten())*len(df_total_merge.Arabs_total_born.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df_total_merge['Jews_and_others_total_death'],y=df_total_merge['Jews_and_others_total_born'],c='r',marker='s',label='Digital')\n",
    "plt.scatter(x=df_total_merge['Arabs_total_death'],y=df_total_merge['Arabs_total_born'],c='k',marker='*',label='Newspaper')\n",
    "plt.legend(numpoints=1,loc=4)\n",
    "\n",
    "plt.plot(df_total_merge['Jews_and_others_total_death'],lr_Jews.predict(df_total_merge['Jews_and_others_total_death'].values.reshape(df_total_merge['Jews_and_others_total_death'].shape[0],1)),c='m',linewidth=3)\n",
    "plt.plot(df_total_merge['Arabs_total_death'],lr_Arabs.predict(df_total_merge['Arabs_total_death'].values.reshape(df_total_merge['Arabs_total_death'].shape[0],1)),c='c',linewidth=3)\n",
    "\n",
    "plt.xlabel('death (Thousands)')\n",
    "plt.ylabel('born (Thousands)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression() # create a linear regression object\n",
    "\n",
    "x = df_total_merge[['Jews_and_others_total_death','Arabs_total_death']]\n",
    "y = df_total_merge['total_death']\n",
    "lr.fit(X=x, y=y);\n",
    "\n",
    "print(df_total_merge.corr())\n",
    "pd.plotting.scatter_matrix(df_total_merge, figsize=(10, 10), diagonal='kde')\n",
    "plt.show()\n",
    "\n",
    "print(\"Slope:\",lr.coef_)\n",
    "print(\"Intercept:\",lr.intercept_)\n",
    "print(\"R2:\",lr.score(x,y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
